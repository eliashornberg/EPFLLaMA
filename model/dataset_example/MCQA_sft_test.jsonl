{"question": "Question: You are doing your ML project. It is a regression task under a square loss. Your neighbor uses linear regression and least squares. You are smarter. You are using a neural net with 10 layers and activations functions $f(x)=3 x$. You have a powerful laptop but not a supercomputer. You are betting your neighbor a beer at Satellite who will have a substantially better scores. However, at the end it will essentially be a tie, so we decide to have two beers and both pay. What is the reason for the outcome of this bet?\n\nOptions:\nA. Because we use exactly the same scheme.\nB. Because it is almost impossible to train a network with 10 layers without a supercomputer.\nC. Because I should have used more layers.\nD. Because I should have used only one layer.", "answer": "A"}
{"question": "Question: (FastText supervised Classifier) The FastText supervised classifier can be modeled as a one-hidden-layer neural network.\n\nOptions:\nA. True\nB. False", "answer": "A"}
{"question": "Question: A model which has a high bias necessarily has a low variance.\n\nOptions:\nA. True\nB. False", "answer": "B"}
{"question": "Question: Consider a regression model where data $(x,y)$ is generated by input $x$ uniformly randomly sampled from $[0,1]$ and $y(x) = x^2 + \\epsilon$,\n\t        where $\\epsilon$ is random noise with mean 0 and variance 1.\n            Two models are carried out for regression:\n            model A is a trained quadratic function $g(x; \\wv) = w_2 x^2 + w_1 x + w_0$ where $\\wv = (w_0, w_1, w_2)^\top\\in\\mathbb R^3$,\n            and model B is a constant function $h(x) = 1/2$.\n            Then compared to model B, model A has ?\n\nOptions:\nA. higher bias, higher variance.\nB. higher bias, lower variance.\nC. lower bias, higher variance.\nD. lower bias, lower variance.", "answer": "C"}
{"question": "Question: (Bayes Nets) We are given a Bayes net involving the variables $X_{1}, \\cdots, X_{n}$. We determine, using our standard rules, that $X_{1} \\perp X_{2} \\mid X_{3}$. Assume now that you delete some edges in the original Bayes net. For the modified Bayes net, is it always true that $X_{1} \\perp X_{2} \\mid X_{3}$ ?\n\nOptions:\nA. True\nB. False", "answer": "B"}
{"question": "Question: Consider the loss function $L: \\R^d \to \\R$, $L(\\wv) = \frac{\beta}{2}\\|\\wv\\|^2$, where $\beta > 0$ is a constant. We run gradient descent on $L$ with a stepsize $\\gamma > 0$ starting from some $\\wv_0 \neq 0$. Which of the statements below is true? ?\n\nOptions:\nA. Gradient descent converges to the global minimum for any stepsize $\\gamma > 0$.\nB. Gradient descent with stepsize $\\gamma = \frac{2}{\beta}$ produces iterates that diverge to infinity ($\\|\\wv_t\\| \to \\infty$ as $t\to \\infty$).\nC. Gradient descent converges in two steps for $\\gamma = \frac{1}{\beta}$ (i.e., $\\wv_2$ is the \textbf{first} iterate attaining the global minimum of $L$).\nD. Gradient descent converges to the global minimum for any stepsize in the interval $\\gamma \\in \big( 0, \frac{2}{\beta}\big)$.", "answer": "D"}
{"question": "Question: The following member of the exponential family represents a scalar Gaussian: $p(y)=\\exp \\left\\{(2,-1)\\left(y, y^{2}\\right)^{\\top}-\\right.$ $\\left.1-\\frac{1}{2} \\ln (\\pi)\\right\\}$. What are the mean $\\mu$ and the variance $\\sigma^{2}$ ?\n\nOptions:\nA. (a) $\\mu=-1, \\sigma^{2}=0$.\nB. (b) $\\mu=0, \\sigma^{2}=0$.\nC. (c) $\\mu=1, \\sigma^{2}=0$.\nD. (d) $\\mu=-1, \\sigma^{2}=\\frac{1}{2}$\nE. (e) $\\mu=0, \\sigma^{2}=\\frac{1}{2}$.\nF. (f) $\\mu=1, \\sigma^{2}=\\frac{1}{2}$.\nG. (g) $\\mu=-1, \\sigma^{2}=1$.\nH. (h) $\\mu=0, \\sigma^{2}=1$.\nI. (i) $\\mu=1, \\sigma^{2}=1$", "answer": "B"}
{"question": "Question:  Consider the Parametric ReLU function defined as\n            $$f(x) = \\left\\{\begin{matrix}\n                    x  & \textup{if}\\; x > 0 \\\n                    ax & \textup{otherwise}\n                \\end{matrix}\right.$$\n            where $a \\in \\R$ is an arbitrary number.\n            Which of the following statements is true regarding the subgradients of $f(x)$ at $x = 0$?\n        ?\n\nOptions:\nA. A subgradient exists even though $f(x)$ is not necessarily differentiable at $x=0$.\nB. A subgradient does not exist at $x=0$.\nC. If a subgradient exists, then it is not unique.\nD. None of the mentioned answers.", "answer": "A"}
{"question": "Question: In principal component analysis, the left singular vectors $\\mathbf{U}$ of a data matrix $\\mathbf{X}$ of shape ( $d$ features, $n$ datapoints) are used to create a new data matrix $\\mathbf{X}^{\\prime}=\\mathbf{U}^{\\top} \\mathbf{X}$. To achieve dimensionality reduction, we keep only certain rows of the matrix $\\mathbf{X}^{\\prime}$. We keep those rows that have:?\n\nOptions:\nA. the lowest variance.\nB. the highest variance.\nC. smallest L2 norm.\nD. L2 norm closest to 1", "answer": "B"}
{"question": "Question: Our task is to classify whether an animal is a dog (class 0) or a cat (class 1) based on the following features: \n        \begin{itemize}\n\t        \\item $x_1$: height\n\t        \\item $x_2$: length of whiskers\n\t        \\item $x_3$: thickness of fur\n        \\end{itemize}\n        We perform standard normal scaling on the training features so that they have a mean of zero and standard deviation of 1. We have trained a Logistic Regression model to determine the probability that the animal is a cat, $p(1 | \\mathbf{x,w})$.\n        Our classifier learns that cats have a lower height and longer whiskers than dogs, while the thickness of fur is not relevant to the classification outcome. Which of the following is true about the weights~$\\wv$ learned by the classifier?\n        ?\n\nOptions:\nA. $w_1 < w_2 < w_3$\nB. $w_1 < w_3 < w_2$\nC. $w_2 < w_1 < w_3$\nD. $w_2 < w_3 < w_1$\nE. $w_3 < w_1 < w_2$\nF. $w_3 < w_2 < w_1$", "answer": "A"}
{"question": "Question: (Neural networks) Training only the first layer of a deep neural network using the logistic loss is equivalent to training a logistic regression over a transformed feature space.\n\nOptions:\nA. True\nB. False", "answer": "A"}
{"question": "Question: Matrix Factorizations: The function $f(\\mathbf{v}):=g\\left(\\mathbf{v} \\mathbf{v}^{\\top}\\right)$ is convex over the vectors $\\mathbf{v} \\in \\mathbb{R}^{2}$, when $g: \\mathbb{R}^{2 \\times 2} \\rightarrow \\mathbb{R}$ is defined as?\n\nOptions:\nA. (a)  if we define $g: \\mathbb{R}^{2 \\times 2} \\rightarrow \\mathbb{R}$ as $g(\\mathbf{X}):=X_{11}$.\nB. (b)  if we define $g: \\mathbb{R}^{2 \\times 2} \\rightarrow \\mathbb{R}$ as $g(\\mathbf{X}):=X_{11}+X_{22}$.", "answer": "B"}
{"question": "Question: Recall that we say that a kernel $K: \\R \times \\R \rightarrow \\R $ is valid if there exists $k \\in \\mathbb{N}$ and $\\Phi: \\R \rightarrow \\R^k$ such that for all $(x, x') \\in \\R \times \\R $, $K(x, x') =  \\Phi(x)^\top \\Phi(x')$. The kernel $K(x, x') = \\cos(x + x')$ is a valid kernel.\n\nOptions:\nA. True\nB. False", "answer": "A"}
{"question": "Question: Consider the composite function $f(x)=g(h(x))$, where all functions are $\\mathbb{R}$ to $\\mathbb{R}$. Which of the following is the weakest condition that guarantees that $f(x)$ is convex?\n\nOptions:\nA. $g(x)$ and $h(x)$ are convex and $g(x)$ and $h(x)$ are increasing\nB. $g(x)$ is convex and $g(x)$ is increasing\nC. $g(x)$ and $h(x)$ are convex and $h(x)$ is increasing\nD. $g(x)$ and $h(x)$ are convex and $g(x)$ is increasing\nE. $g(x)$ is convex and $g(x)$ and $h(x)$ are increasing\nF. $h(x)$ is convex and $g(x)$ and $h(x)$ are increasing\nG. $g(x)$ is convex and $h(x)$ is increasing", "answer": "D"}
{"question": "Question: In a Gaussian Mixture Model, assuming $D, K \\ll N$, the number of free parameters, after marginalization of the latent variables $z_{n}$, is?\n\nOptions:\nA. (a)  quadratic in $D$\nB. (b)  cubic in $D$\nC. (c)  linear in $N$", "answer": "C"}
{"question": "Question: Consider a linear regression problem with $N$ samples where the input is in $D$-dimensional space, and all output values are $y_{i} \\in\\{-1,+1\\}$. Which of the following statements is correct?\n\nOptions:\nA. (a)  linear regression cannot \"work\" if $N \\gg D$\nB. (b)  linear regression cannot \"work\" if $N \\ll D$\nC. (c)  linear regression can be made to work perfectly if the data is linearly separable", "answer": "B"}
{"question": "Question: Which of the following statements about the $\\mathrm{SVD}$ of an $N \\times D$ matrix $\\mathbf{X}$ are correct?\n\nOptions:\nA. We can compute the singular values of $\\mathbf{X}$ by computing the eigenvalues of $\\mathbf{X X}^{\\top}$. This has complexity $O\\left(N^{3}\\right)$.\nB. We can compute the singular values of $\\mathbf{X}$ by computing the eigenvalues of $\\mathbf{X X}^{\\top}$. This has complexity $O\\left(D^{3}\\right)$.\nC. We can compute the singular values of $\\mathbf{X}$ by computing the eigenvalues of $\\mathbf{X}^{\\top} \\mathbf{X}$. This has complexity $O\\left(N^{3}\\right)$.\nD. We can compute the singular values of $\\mathbf{X}$ by computing the eigenvalues of $\\mathbf{X}^{\\top} \\mathbf{X}$. This has complexity $O\\left(D^{3}\\right)$.\nE. We can compute the singular values of $\\mathbf{X}$ by computing the eigenvalues of $\\mathbf{X} \\mathbf{X}^{\\top}$ if only if $\\mathbf{X}$ is a square matrix. This has complexity $O\\left(D^{3}\\right)=O\\left(N^{3}\\right)$.", "answer": "D"}
{"question": "Question: (Backpropagation) Training via the backpropagation algorithm always learns a globally optimal neural network if there is only one hidden layer and we run an infinite number of iterations and decrease the step size appropriately over time.\n\nOptions:\nA. True\nB. False", "answer": "B"}
{"question": "Question: Which of the following statements are correct?\n\nOptions:\nA. One iteration of standard SGD for SVM costs roughly $\\Theta(D)$, where $D$ is the dimension.\nB. Unions of convex sets are convex.\nC. Hinge loss (as in SVMs) is typically preferred over L2 loss (least squares loss) in classification tasks.\nD. In PCA, the first principal direction is the eigenvector of the data matrix $\\boldsymbol{X}$ with largest associated eigenvalue.\nE. MSE (mean squared error) is typically more sensitive to outliers than MAE (mean absolute error).\nF. One iteration of standard SGD for logistic regression costs roughly $\\Theta(N D)$, where $N$ is the number of samples and $D$ is the dimension.", "answer": "A"}
{"question": "Question: Which of the following statements is \textbf{incorrect} ? Training a model with $L_1$-regularization ...\n\nOptions:\nA. can reduce the storage cost of the final model.\nB. is used to help escaping local minima during training.\nC. can reduce overfitting.\nD. can be named Lasso regression when in combination with an MSE loss function and a linear model.", "answer": "B"}
{"question": "Question: Consider the following joint distribution on $X$ and $Y$, where both random variables take on the values $\\{0,1\\}: p(X=$ $0, Y=0)=0.1, p(X=0, Y=1)=0.2, p(X=1, Y=0)=0.3, p(X=1, Y=1)=0.4$. You receive $X=1$. What is the largest probability of being correct you can achieve when predicting $Y$ in this case?\n\nOptions:\nA. $\\frac{1}{3}$\nB. $\\frac{3}{4}$\nC. $\\frac{1}{7}$\nD. $0$\nE. $1$\nF. $\\frac{2}{3}$\nG. $\\frac{6}{7}$\nH. $\\frac{4}{7}$\nI. $\\frac{3}{7}$\nJ. $\\frac{1}{4}$\nK. $\\frac{2}{4}$", "answer": "H"}
{"question": "Question: In Text Representation learning, which of the following statements is correct?\n\nOptions:\nA. Learning GloVe vectors can be done using SGD in a streaming fashion, by streaming through the input text only once.\nB. Every recommender systems algorithm for learning a matrix factorization $\\boldsymbol{W} \\boldsymbol{Z}^{\\top}$ approximating the observed entries in least square sense does also apply to learn GloVe word vectors.\nC. FastText performs unsupervised learning of word vectors.\nD. If you fix all word vectors, and only train the remaining parameters, then FastText in the two-class case reduces to being just a linear classifier.", "answer": "A"}
{"question": "Question: Nearest neighbor classifiers cannot be used for regression because they rely on majority voting, which is not suited for continuous labels.\n\nOptions:\nA. True\nB. False", "answer": "A"}
{"question": "Question: (Text Representation Learning, GloVe) Learning GloVe word vectors is identical to approximating the observed entries of the word/context co-occurence counts by $\\mathbf{W} \\mathbf{Z}^{\\top}$, in the least square sense, if the $f_{d n}$ weights are set to 1 for all observed entries.\n\nOptions:\nA. True\nB. False", "answer": "A"}
{"question": "Question: Generative Adversarial Networks use the generator and discriminator models during training but only the discriminator for data synthesis.\n\nOptions:\nA. True\nB. False", "answer": "B"}
{"question": "Question: Consider our standard least-squares problem $$ \\operatorname{argmin}_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w})=\\operatorname{argmin}_{\\mathbf{w}} \\frac{1}{2} \\sum_{n=1}^{N}\\left(y_{n}-\\mathbf{x}_{n}^{\\top} \\mathbf{w}\\right)^{2}+\\frac{\\lambda}{2} \\sum_{d=1}^{D} w_{d}^{2} $$ Here, $\\left\\{\\left(\\mathbf{x}_{n} y_{n}\\right)\\right\\}_{n=1}^{N}$ is the data. The $N$-length vector of outputs is denoted by $\\mathbf{y}$. The $N \\times D$ data matrix is called $\\mathbf{X}$. It's rows contain the tuples $\\mathbf{x}_{n}$. Finally, the parameter vector of length $D$ is called $\\mathbf{w}$. (All just like we defined in the course). Mark any of the following formulas that represent an equivalent way of solving this problem.\n\nOptions:\nA. $\\operatorname{argmin}_{\\boldsymbol{\\alpha}} \\frac{1}{2} \\boldsymbol{\\alpha}^{\\top}\\left(\\mathbf{X X}^{\\top}+\\lambda \\mathbf{I}_{N}\\right) \\boldsymbol{\\alpha}-\\boldsymbol{\\alpha}^{\\top} \\mathbf{y}$\nB. $\\operatorname{argmin}_{\\mathbf{w}} \\sum_{n=1}^{N}\\left[1-y_{n} \\mathbf{x}_{n}^{\\top} \\mathbf{w}\\right]_{+}+\\frac{\\lambda}{2}\\|\\mathbf{w}\\|^{2}$. Recall: $[z]_{+}=\\max \\{0, z\\}$\nC. $\\operatorname{argmin}_{\\mathbf{w}}-\\log p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) p(\\mathbf{w})$, where $p(\\mathbf{w})$ correspond to the density of a $D$-length vector of iid zero-mean Gaussians with variance $1 / \\lambda$ and $p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w})$ corresponds to the density of a vector of length $N$ of independent Gaussians of mean $\\mathbf{x}_{n}^{\\top} \\mathbf{w}$, variance 1 and observation $\\mathbf{y}_{n}$ for component $n$.\nD. $\\square \\operatorname{argmin}_{\\mathbf{w}} \\frac{1}{2} \\sum_{n=1}^{N} \\ln \\left(1+e^{\\mathbf{x}_{n}^{\\top} \\mathbf{w}}\\right)-y_{n} \\mathbf{x}_{n}^{\\top} \\mathbf{w}$\nE. $\\operatorname{argmin}_{\\mathbf{w}} \\frac{1}{2}\\|\\mathbf{y}-\\mathbf{X} \\mathbf{w}\\|^{2}+\\frac{\\lambda}{2}\\|\\mathbf{w}\\|^{2}$", "answer": "E"}
{"question": "Question: (Weight initialization) The choice of weight initialization will not impact the optimization behavior of the neural network.\n\nOptions:\nA. True\nB. False", "answer": "B"}
{"question": "Question: The KNN algorithm needs a notion of distance to assess which points are ``nearest''.\n\t                Identify the distance measures that can be used in the KNN algorithm. \n                    (a) Euclidean Distance : distance associated to the $L_2$ norm $\\|xv\\|_2 := \\sqrt{x_1^2+\\dots+x_D^2}$\n\t\t            (b) Manhattan Distance : distance associated to the $L_1$ norm $\\|xv\\|_1 := |x_1|+\\dots+|x_D|$\n\t\t            (c) Distance associated to the $L_4$ norm $\\|xv\\|_4 := \big(|x_1|^4+\\dots+|x_D|^4\big)^{1/4}$\n\t                ?\n\nOptions:\nA. only a\nB. only b\nC. only c\nD. only a and b\nE. only a and c\nF. only b and c\nG. a, b and c", "answer": "G"}
{"question": "Question: Let $n$ be an integer such that $n\\geq 2$ and let  $A \\in \\R^{n\times n}$, and $xv \\in \\R^n$, consider the function $f(xv) = xv^\top A xv$ defined over $\\R^n$. Which of the following is the gradient of the function $f$? ?\n\nOptions:\nA. $2 xv^\top A$\nB. $2Axv$\nC. $A^\top xv + Axv$\nD. $2A^\top xv$", "answer": "B"}
{"question": "Question: Which of the following statements are true?\n\nOptions:\nA. The more training examples, the more accurate the prediction of a $k$-nearest-neighbor classifier.\nB. k-nearest-neighbors cannot be used for regression.\nC. A $k$-nearest-neighbor classifier is sensitive to outliers.\nD. Training a $k$-nearest-neighbor classifier takes more computational time than applying it / using it for prediction.", "answer": "A"}
{"question": "Question: Assume that you get a confidence interval of size $\\delta$ for some problem given $N$ iid samples. Expressed as a function of $N$, how many iid samples do you need to get a confidence interval of $\\operatorname{size} \\delta / 3 ?$?\n\nOptions:\nA. $3 N$\nB. $N/3$\nC. $N^3$\nD. $9N$\nE. $\\sqrt{3 N}$\nF. $e^{3 N}$", "answer": "D"}
{"question": "Question: Consider:Non-terminals: S (top-level), NP (for \"noun phrase\"), VP (for \"verbal phrase\"), N (for \"Noun\"), V (for \"Verb\"), Det (for \"Determiner\").PoS tags: N, V, DetTerminals: I, yesterday, in, rain, went, home, the, cat, goOut of the following, select the ones which are possible valid \"syntactic rules\" as defined in a context-free grammar for processing (a tiny part of) English.A penalty will be applied for any incorrect answers.\n\nOptions:\nA. S\u00a0\u2192 NP VP\nB. NP \u2192 Det N\nC. V \u2192 VP N\u00a0\nD. NP \u2192 N\nE. VP \u2192 VP NP\nF. VP NP \u2192 V N\nG. VP \u2192 the cat\nH. Det \u2192 went\nI. Det N \u2192 NP\nJ. S \u2192 VP", "answer": "A"}
{"question": "Question: Select all the statements that are true.A penalty will be applied for any incorrect answers selected.\n\nOptions:\nA. The Luhn law states that if a set of words are ranked by the decreasing order of their frequencies, the high-ranked words are the best features for identifying the topics that occur in the document collection.\nB. The order of words are ignored in the bag-of-words model.\nC. High values of document frequency means that the word is not very discriminative.\nD. Documents that are orthogonal to each other gives a cosine similarity measure of 1.\nE. Cosine similarity is independent of the length of the documents.", "answer": "B"}
{"question": "Question: What could Out of Vocabulary (OoV) forms consist of?\u00a0Select all that apply.A penalty will be applied for wrong answers.\n\nOptions:\nA. Words from the lexicon\nB. Words borrowed from other languages\nC. Words with spelling errors\nD. Neologisms\nE. Abbreviations", "answer": "B"}
{"question": "Question: For this question,\u00a0one or more\u00a0assertions can be correct. Tick only the correct assertion(s).\u00a0There will be a penalty for wrong assertions ticked.Which of the following associations can be considered as illustrative examples for inflectional\nmorphology (with here the simplifying assumption that canonical forms are restricted to the roots\nonly)?\n\nOptions:\nA. (activate, action)\nB. (hypothesis, hypotheses)\nC. (to go, went)\nD. (speaking, talking)", "answer": "A"}
{"question": "Question: What is a good distance metric to be used when you want to compute the similarity between documents independent of their length?A penalty will be applied for any incorrect answers.\n\nOptions:\nA. Cosine similarity\nB. Euclidean distance\nC. Manhattan distance\nD. Chi-squared distance", "answer": "A"}
{"question": "Question: Select all statements that are true.A penalty will be applied for any wrong answers.\n\nOptions:\nA. Phrase-structure grammars are relatively better suited for fixed-order languages than free-order languages.\nB. Dependency grammars describe functional dependencies between words in a sequence.\nC. Phrase-structure grammars better describe selectional constraints.\nD. The expressive power of context-free grammars are higher than that of context-dependent grammars.\nE. Any context-free grammar can be transformed into Chomsky-Normal form.\nF. Dependency grammars\u00a0better describe\u00a0positional constraints.", "answer": "A"}
{"question": "Question: Select which statements are true about the CYK algorithm.A penalty will be applied for any incorrect answers.\n\nOptions:\nA. It is a top-down chart parsing algorithm.\nB. Its time complexity is \\( O(n^3) \\), where\u00a0\\( n \\) is the length of sequence of words to be parsed.\nC. Its time complexity decreases when the grammar is regular.\nD. The Context-Free Grammar used with the CYK algorithm has to be converted into extended Chomsky normal form.\nE. It not only generates the syntactic interpretations of the sequence to be analyzed but also generates the syntactic interpretations of all the sub-sequences of the sequence to be analyzed.", "answer": "A"}
{"question": "Question: The edit distance between \u201cpiece\u201d and \u201cpeace\u201d is(Penalty for wrong ticks)?\n\nOptions:\nA. 5\nB. 3\nC. 1, if considering insertion and deletion only\nD. 2, if considering insertion and deletion only\nE. 3, if considering insertion and deletion only\nF. 1, if considering insertion, deletion and substitution\nG. 2, if considering insertion, deletion and substitution\nH. 3, if considering insertion, deletion and substitution\nI. 1, if considering insertion, deletion, transposition and substitution\nJ. 2, if considering insertion, deletion, transposition and substitution\nK. 3, if considering insertion, deletion, transposition and substitution", "answer": "F"}
{"question": "Question: Select all statements that are true.A penalty will be applied for any wrong answers.\n\nOptions:\nA. The analyzer functionality of a parser determines the set of all possible associated syntactic structures for any syntactically correct sentence.\nB. The recognizer functionality of a parser decides if a given sequence of words is syntactically correct or not.\nC. For a sentence to be acceptable in general, it is sufficient to satisfy the positional and selectional constraints of a given language.\nD. Determining whether a sentence has a pragmatic meaning depends on the context that is available.\nE. Syntactic ambiguity has no effect on the algorithmic complexity of parsers.", "answer": "A"}
{"question": "Question: \nYour aim is to evaluate a movie review analysis system, the purpose of which is to determine whether a review is globally positive or negative.\nFor each movie review, such a system outputs one of the following classes: positive and negative.\nTo perform your evaluation, you collect a large set of reviews and have it annotated by two human annotators. This corpus contains 95% of negative reviews (this 95% ratio is for this first question only and may change in the next\n            questions).\n\nWhat metrics do you think are appropriate to evaluate the system on this corpus?\n\nYou will get a penalty for wrong ticks.\n?\n\nOptions:\nA. Cohen's kappa\nB. accuracy\nC. precision\nD. recall\nE. standard deviation\nF. F1-score", "answer": "F"}
{"question": "Question: Select the statements that are true.A penalty will be applied to any incorrect answers selected.\n\nOptions:\nA. Information retrieval is the selection of documents relevant to a query from an unstructured collection of documents.\nB. Different IR systems can differ in the way they represent documents, represent queries, and define the relevance measure between documents and queries.\nC. The vector space model represents documents as vectors derived from the distribution of indexing terms in the document.\nD. The dimensionality of the vector space does not depend on the size of the indexing vocabulary.\nE. Use of filters during indexing results in less informative indexes.", "answer": "A"}
{"question": "Question: Consider the following lexicon \\(L\\):\nboy    : Adj, N\nboys   : N\nblue   : Adj, N\ndrink  : N, V\ndrinks : N, V\nNice   : Adj, N\n\nWhen using an order-1 HMM model (using \\(L\\)) to tag the word sequence:\"Nice boys drink blue drinks\"does the tag of drink\u00a0depend on the tag of nice?\n\n?\n\nOptions:\nA. yes, because the HMM approach relies on a global maximum.\nB. no, the hypotheses make the two tags independent from each other.", "answer": "B"}
{"question": "Question: Select all true statements.A penalty will be applied for any incorrect answers.\n\nOptions:\nA. The k-means algorithm always converges because at each step it minimizes the intra-class variance.\nB. The k-NN algorithm is a non-hierarchical, non-overlapping clustering method.\nC. The k-means algorithm always converges into a global minimum.\nD. In mapping methods used for visualization, the target space is considered a sub-space of the original space.\nE. In textual classification, the objects are always full length documents.\nF. Non-parametric methods for classification does not involve any parameter.", "answer": "A"}
{"question": "Question: Select the morpho-syntactic categories that do not carry much semantic content and are thus usually filtered-out from indexing.\n\nOptions:\nA. Determiners\u00a0\nB. Conjunctions\nC. Nouns\nD. Adjectives\nE. Verbs", "answer": "A"}
{"question": "Question: Which of the following are parameters involved in the choice made by an order-1 HMM model for PoS tagging knowing that its output isthis/Pron is/V a/Det good/Adj question/Nand that neither \"is\" nor \"question\" can be adjectives, and that \"question\" can also not be a determiner.(Penalty for wrong ticks.)?\n\nOptions:\nA. P(N|question)\nB. P(question|N)\nC. P(question|Adj N)\nD. P(question|N Adj)\nE. P(this)\nF. P(this is)\nG. P(this V)\nH. P(Pron)\nI. P(Pron V)\nJ. P(Pron is)\nK. P(Det|Adj)\nL. P(Adj|Det)\nM. P(Adj|V Det)\nN. P(Adj|Det V)\nO. P(Det|V Adj)\nP. P(Det|Pron V)\nQ. P(Adj|a)\nR. P(question|Adj)", "answer": "B"}
{"question": "Question: Consider the\u00a0table of term frequencies for 3 documents D1, D2, and D3D1\u00a0\u00a0\u00a0\u00a0\u00a0 D2\u00a0\u00a0\u00a0\u00a0\u00a0 D3car740auto330insurance\u00a0\u00a0\u00a0\u00a0 037Considering the bag of words model , with TF-IDF weightning and cosine similarity metric, which document (D1, D2 or D3) is most relevant to the following query:\"car insurance\"?\n\nOptions:\nA. D1\nB. D2\nC. D3", "answer": "C"}
{"question": "Question: Consider the following context-free grammar \\(G\\) (where \\(\\text{S}\\) is the top-level symbol):\n\n\\(R_{01}: \\text{S} \\rightarrow \\text{NP VP}\\)\n\\(R_{02}: \\text{NP} \\rightarrow \\text{NP0}\\)\n\\(R_{03}: \\text{NP} \\rightarrow \\text{Det NP0}\\)\n\\(R_{04}: \\text{NP0} \\rightarrow \\text{N}\\)\n\\(R_{05}: \\text{NP0} \\rightarrow \\text{Adj N}\\)\n\\(R_{06}: \\text{NP0} \\rightarrow \\text{NP0 PNP}\\)\n\\(R_{07}: \\text{VP} \\rightarrow \\text{V}\\)\n\\(R_{08}: \\text{VP} \\rightarrow \\text{V NP}\\)\n\\(R_{09}: \\text{VP} \\rightarrow \\text{V NP PNP}\\)\n\\(R_{10}: \\text{PNP} \\rightarrow \\text{Prep NP}\\)\n\ncomplemented by the lexicon \\(L\\):\na        : Det\nblue     : Adj, N\ndrink    : N, V\ndrinks   : N, V\nfriends  : N\nfrom     : Prep\ngave     : V\nletter   : N\nmy       : Det\nneighbor : N\nnice     : Adj, N\nof       : Prep\npostman  : N\nran      : V\nthe      : Det\nto       : PrepHow many (syntactic and lexical) rules does the extended Chomsky Normal Form grammar equivalent to \\(G\\) contain, if produced as described in the parsing lecture?\n\nOptions:\nA. the grammar \\(G\\) cannot be converted to extended Chomsky Normal Form\nB. the grammar \\(G\\) already is in extended Chomsky Normal Form\nC. 11 rules\nD. 31 rules\nE. 48 rules", "answer": "D"}
{"question": "Question: Dans un syst\u00e8me ind\u00e9formable, comment est d\u00e9finie la tension induite ? (plusieurs r\u00e9ponses possibles)?\n\nOptions:\nA. l'oppos\u00e9 (-) de l'int\u00e9grale du champ d'induction magn\u00e9tique (densit\u00e9 de flux) sur une surface\nB. l'oppos\u00e9 (-) de l'int\u00e9grale du champ \u00e9lectrique sur un contour ferm\u00e9\nC. la d\u00e9riv\u00e9e par rapport au temps du champ d'induction magn\u00e9tique (densit\u00e9 de flux)\nD. la d\u00e9riv\u00e9e par rapport au temps du flux totalis\u00e9", "answer": "A"}
{"question": "Question: Que dit la loi d'Ohm g\u00e9n\u00e9ralis\u00e9e \u00e0 propos de la tension au bornes d'une bobine travers\u00e9e par un courant ? (une seule r\u00e9ponse possible)?\n\nOptions:\nA. rien\nB. qu'elle est \u00e9gale \u00e0 la r\u00e9sistance du fil multipli\u00e9 par le courant\nC. qu'elle est \u00e9gale \u00e0 la r\u00e9sistance du fil multipli\u00e9 par le courant, plus la variation du flux totalis\u00e9\nD. qu'elle est \u00e9gale \u00e0 la r\u00e9sistance du fil multipli\u00e9 par le courant, mois la variation du flux totalis\u00e9", "answer": "A"}
{"question": "Question: Combien vaut la perm\u00e9abilit\u00e9 magn\u00e9tique du vide ? (une seule r\u00e9ponse possible)?\n\nOptions:\nA. 4*\u03c0*10\nB. 2*\u03c0*10\nC. 4*\u03c0*10\nD. 2*\u03c0*10", "answer": "A"}
{"question": "Question: Quelle est l'expression de la force pour un syst\u00e8me \u00e9lectrodynamique ? (une seule r\u00e9ponse possible)?\n\nOptions:\nA. \\[ F = \\frac{d\u039b_{ab}}{dx} * \u0398_a * \u0398_b \\]\nB. \\[ F = \\frac{1}{2} \\frac{d\u039b_a}{dx} * \u0398_a^2 + \\frac{d\u039b_{ab}}{dx} * \u0398_a * \u0398_b \\]\nC. \\[ F = \\frac{1}{2} \\frac{d\u039b_b}{dx} * \u0398_b^2 \\]\nD. \\[ F = \\frac{1}{2} \\frac{d\u039b_a}{dx} * \u0398_a^2 + \\frac{1}{2} \\frac{d\u039b_b}{dx} * \u0398_b^2 + \\frac{d\u039b_{ab}}{dx} * \u0398_a * \u0398_b \\]", "answer": "A"}
{"question": "Question: L'unit\u00e9 du flux magn\u00e9tique est en : (plusieurs r\u00e9ponses possibles)?\n\nOptions:\nA. volt/seconde (V/s)\nB. volt*seconde (V*s)\nC. Weber (Wb)\nD. Tesla (T)", "answer": "A"}
{"question": "Question: In JOS, suppose a value is passed between two Envs. What is the minimum number of executed system calls?\n\nOptions:\nA. 1\nB. 2\nC. 3\nD. 4", "answer": "B"}
{"question": "Question: In an x86 multiprocessor system with JOS, select all the correct options. Assume every Env has a single thread.\n\nOptions:\nA. Two Envs could run on the same processor simultaneously.\nB. Two Envs could run on two different processors simultaneously.\nC. One Env could run on two different processors simultaneously.\nD. One Env could run on two different processors at different times.", "answer": "B"}
{"question": "Question: Which of the following lock acquisition orders (locks are acquired from left to right), for thread 1 (T1) and thread 2 (T2), will result in a deadlock ? Assume that A, B, C, D are lock instances.\n\nOptions:\nA. T1: A,B,C,D      T2: A,B,C,D\nB. T1: A,D,C,B      T2: A,D,C,B\nC. T1: A,B,C,D      T2: D,C,B,A\nD. T1: A,B,C,D      T2: A,B,E,F\nE. T1: A,B,C,D      T2: E,B,A,F", "answer": "C"}
{"question": "Question: Once paging is enabled, load instruction / CR3 register / Page Table entry uses Virtual or Physical address?\n\nOptions:\nA. Physical / Physical / Physical\nB. Physical / Physical / Virtual\nC. Virtual / Physical / Physical\nD. Virtual / Virtual / Virtual\nE. Virtual / Virtual / Physical", "answer": "C"}
{"question": "Question: In x86, select all synchronous exceptions?\n\nOptions:\nA. Divide error\nB. Timer\nC. Page Fault\nD. Keyboard", "answer": "A"}
{"question": "Question: Select all valid answers about UNIX-like shell.\n\nOptions:\nA. The shell is a program, that runs in user-space.\nB. The shell is a program, that runs in kernel-space.\nC. The shell is a program, which reads from standard input.\nD. The shell is a function inside kernel.\nE. The shell is the layer, which has to be always used for communicating with kernel.\nF. The shell must run only in a single instance. Multiple running instances cause memory corruption.\nG. The shell is a user interface for UNIX-like systems.", "answer": "A"}
{"question": "Question: In which of the following cases does the TLB need to be flushed?\n\nOptions:\nA. Inserting a new page into the page table for a user-space application.\nB. Deleting a page from the page table.\nC. Changing the read/write permission bit in the page table.\nD. Inserting a new page into the page table for kernel.", "answer": "A"}
{"question": "Question: In JOS and x86, which register stores the system call number when invoking a system call?\n\nOptions:\nA. ecx\nB. eip\nC. eax\nD. esp\nE. No register is required, and the syscall number is followed by int instruction, e.g. int 0x30.", "answer": "C"}
{"question": "Question: What is the content of the superblock in the JOS file system?\n\nOptions:\nA. List of all directories\nB. List of all files\nC. List of all blocks\nD. List of all inodes\nE. Total number of blocks on disk\nF. Magic number identifying the file system\nG. Node with the root directory ('/')", "answer": "F"}
{"question": "Question: In JOS, after finishing the execution of a user-level page fault handler, how is the program control flow transferred back to the program? (You may get insights from the code snippet of _pagefault_upcall.)?\n\nOptions:\nA. The control flow will be transferred to kernel first, then to Env that caused the page fault.\nB. The control flow will be transferred to Env that caused the page fault directly.", "answer": "B"}
{"question": "Question: Which flag prevents user programs from reading and writing kernel data?\n\nOptions:\nA. PTE_P\nB. PTE_U\nC. PTE_D\nD. PTE_W", "answer": "B"}
{"question": "Question: Which of the following operations would switch the user program from user space to kernel space?\n\nOptions:\nA. Dividing integer by 0.\nB. Calling sin() in math library.\nC. Invoking read() syscall.\nD. Jumping to an invalid address.", "answer": "C"}
{"question": "Question: Suppose a file system used only for reading immutable files in random fashion. What is the best block allocation strategy?\n\nOptions:\nA. Linked-list allocation\nB. Continuous allocation\nC. Index allocation with B-tree\nD. Index allocation with Hash-table", "answer": "C"}
{"question": "Question: Select valid answers about file descriptors (FD):?\n\nOptions:\nA. The value of FD is unique for every file in the operating system.\nB. FD is usually used as an argument for read and write.\nC. FD is constructed by hashing the filename.\nD. FDs are preserved after fork() and can be used in the new process pointing to the original files.", "answer": "A"}
{"question": "Question: What are the drawbacks of non-preemptive scheduling compared to preemptive scheduling?\n\nOptions:\nA. It can lead to starvation especially for those real-time tasks\nB. Less computational resources need for scheduling and takes shorted time to suspend the running task and switch the context.\nC. Bugs in one process can cause a machine to freeze up\nD. It can lead to poor response time for processes", "answer": "A"}
{"question": "Question: If you write \"hello\" to a file in a JOS file system. Right after the write operation, the computer crashes. Is the content \"hello\" persisted (or written) on the disk?\n\nOptions:\nA. Yes\nB. No", "answer": "B"}
{"question": "Question: In JOS and x86, please select all valid options for a system call.\n\nOptions:\nA. A system call is for handling interrupts like dividing zero error and page fault.\nB. In user mode, before and after a system call instruction(such as int 0x30), the stack pointer(esp in x86) stays the same.\nC. During the execution of a system call, when transfering from user mode to kernel mode, the stack pointer(esp in x86) stays the same.", "answer": "A"}
{"question": "Question: In JOS, suppose one Env sends a page to another Env. Is the page copied?\n\nOptions:\nA. Yes\nB. No", "answer": "B"}
{"question": "Question: Suppose traditional inode pointer structure in ext3, i.e. 12 direct pointers, 1 singly, 1 doubly and 1 triply indirect pointer. Further suppose block size of 1kB and a 64-bit pointer. What is the maximal possible size for a single file?\n\nOptions:\nA. 512kB\nB. 2MB\nC. 4MB\nD. 10MB\nE. 1GB\nF. 4GB", "answer": "F"}
{"question": "Question: What is the worst case complexity of listing files in a directory? The file system implements directories as hash-tables.\n\nOptions:\nA. $O(1)$\nB. $O(number of direntries in the directory)$\nC. $O(size of the file system)$\nD. $O(number of direntries in the file system)$\nE. $O(log(number of direntries in the directory))$", "answer": "B"}
{"question": "Question: In x86, what are the possible ways to transfer arguments when invoking a system call? For example, in the following code, string and len are sys_cputs\u2019s arguments.\n\nOptions:\nA. Stack\nB. Registers\nC. Instructions", "answer": "A"}
{"question": "Question: What is the content of the inode?\n\nOptions:\nA. Filename\nB. File mode\nC. Hard links counter\nD. String with the name of the owner\nE. File size\nF. Capacity of the whole file system\nG. Index structure for data blocks", "answer": "B"}
{"question": "Question: Assume a user program executes following tasks. Select all options that will use a system call.\n\nOptions:\nA. Read the user's input \"Hello world\" from the keyboard.\nB. Write \"Hello world\" to a file.\nC. Encrypt \"Hello world\" by AES.\nD. Send \"Hello world\" to another machine via Network Interface Card.", "answer": "A"}
{"question": "Question: In which of the following cases does JOS acquire the big kernel lock?\n\nOptions:\nA. Processor traps in user mode\nB. Processor traps in kernel mode\nC. Switching from kernel mode to user mode\nD. Initialization of application processor", "answer": "B"}
{"question": "Question: Given that JOS has correctly initialized the IDT and installed all the interrupt handlers. Which of the following will JOS do if the CPU with CPL = 3 tries to read the memory in data segment with DPL = 0?\n\nOptions:\nA. Calling the Page Fault Handler.\nB. Calling the General Protection Fault handler.\nC. Shuting down the system .\nD. Reading out the memory content successfully.", "answer": "B"}
{"question": "Question: Suppose we run JOS and set a breakpoint at syscall (in lib/syscall.c). What are the Current Privilege Level (CPL) before invoking the syscall function and after executing the int 0x30 instruction?\n\nOptions:\nA. 0 3\nB. 0 0\nC. 3 0\nD. 3 3", "answer": "C"}
{"question": "Question: Which of the following scheduler policies are preemptive?\n\nOptions:\nA. FIFO (First In, First Out)\nB. SJF (Shortest Job First)\nC. STCF (Shortest Time to Completion First)\nD. RR (Round Robin)", "answer": "C"}